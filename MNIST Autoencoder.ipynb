{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:\n",
    "Zvi Lapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Neural Network Learning\n",
    "\n",
    "In this notebook will use denoising autoencoder on mnist data sent to learn a feature extractor and then use knn algorithm to predict an images class and will use tsne algo to visualize the predictions as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import pylab as Plot\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "import matplotlib.pyplot as plt\n",
    "from libs.utils import corrupt\n",
    "import platform\n",
    "import math\n",
    "import operator \n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import offsetbox\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be 3.5.2\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "\n",
    "The autoencoder is of dimensions 784, 512, 256, 30, 256, 512, 784 and the goal is to have the neural network reproduce (day dream) the input image in order to have use the layer of 30 as feature extractor. Meaning the training done to reproduce the digit will be used as a image to vec high level feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autoencoder(dimensions=[784, 512, 256, 30]):\n",
    "\n",
    "    # input to the network\n",
    "    x = tf.placeholder(tf.float32, [None, dimensions[0]], name='x')\n",
    "\n",
    "    corrupt_prob = tf.placeholder(tf.float32, [1])\n",
    "    current_input = corrupt(x) * corrupt_prob + x * (1 - corrupt_prob)\n",
    "\n",
    "    # Build the encoder\n",
    "    encoder = []\n",
    "    for layer_i, n_output in enumerate(dimensions[1:]):\n",
    "        n_input = int(current_input.get_shape()[1])\n",
    "        W = tf.Variable(\n",
    "            tf.random_uniform([n_input, n_output],\n",
    "                              -1.0 / math.sqrt(n_input),\n",
    "                              1.0 / math.sqrt(n_input)))\n",
    "        b = tf.Variable(tf.zeros([n_output]))\n",
    "        encoder.append(W)\n",
    "        output = tf.nn.tanh(tf.matmul(current_input, W) + b)\n",
    "        current_input = output\n",
    "    # latent representation\n",
    "    z = current_input\n",
    "    encoder.reverse()\n",
    "    # Build the decoder using the same weights\n",
    "    for layer_i, n_output in enumerate(dimensions[:-1][::-1]):\n",
    "        W = tf.transpose(encoder[layer_i])\n",
    "        b = tf.Variable(tf.zeros([n_output]))\n",
    "        output = tf.nn.tanh(tf.matmul(current_input, W) + b)\n",
    "        current_input = output\n",
    "    # now have the reconstruction through the network\n",
    "    y = current_input\n",
    "    # cost function measures pixel-wise difference\n",
    "    cost = tf.sqrt(tf.reduce_mean(tf.square(y - x)))\n",
    "    return {'x': x, 'z': z, 'y': y,\n",
    "            'corrupt_prob': corrupt_prob,\n",
    "            'cost': cost}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(y):\n",
    "    for i in range(len(y)):\n",
    "        if y[i]:\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "def train_mnist(start_epoch=0, n_epochs = 10000, restore=False, save=True):   \n",
    "    \n",
    "    # load MNIST as before\n",
    "   \n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    mean_img = np.mean(mnist.train.images, axis=0)\n",
    "    ae = autoencoder(dimensions=[784, 512, 256, 30])\n",
    "    \n",
    "\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(ae['cost'])\n",
    "\n",
    "    \n",
    "    # We create a session to use the graph\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    \n",
    "    directory='saved_models'\n",
    "    if restore:\n",
    "        print(\"Restoring\")\n",
    "        saver.restore(sess,'./'+directory+'/model.ckpt-'+str(start_epoch))\n",
    "        print(\"Restored\")\n",
    "\n",
    "    \n",
    "    # Fit all training data\n",
    "    batch_size = 50\n",
    "    \n",
    "    for epoch_i in range(start_epoch,n_epochs):\n",
    "        for batch_i in range(mnist.train.num_examples // batch_size):\n",
    "            batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "            train = np.array([img - mean_img for img in batch_xs])\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                ae['x']: train, ae['corrupt_prob']: [1.0]})\n",
    "        print(epoch_i, sess.run(ae['cost'], feed_dict={\n",
    "            ae['x']: train, ae['corrupt_prob']: [1.0]}))\n",
    "        #verify(sess)\n",
    "        if save:\n",
    "            if ((epoch_i%10)==0):\n",
    "                saver.save(sess, directory+'/model.ckpt',global_step=epoch_i)\n",
    "    \n",
    "    # Plot example reconstructions\n",
    "    n_examples = 15\n",
    "    test_xs, _ = mnist.test.next_batch(n_examples)\n",
    "    test_xs_norm = np.array([img - mean_img for img in test_xs])\n",
    "    recon = sess.run(ae['y'], feed_dict={\n",
    "        ae['x']: test_xs_norm, ae['corrupt_prob']: [0.0]})\n",
    "    fig, axs = plt.subplots(2, n_examples, figsize=(10, 2))\n",
    "    for example_i in range(n_examples):\n",
    "        axs[0][example_i].imshow(\n",
    "            np.reshape(test_xs[example_i, :], (28, 28)))\n",
    "        axs[1][example_i].imshow(\n",
    "            np.reshape([recon[example_i, :] + mean_img], (28, 28)))\n",
    "    fig.show()\n",
    "    plt.draw()\n",
    "    \n",
    "    #predict on test\n",
    "    test_xs, test_ys = mnist.test.next_batch(mnist.test.num_examples)\n",
    "\n",
    "\n",
    "    hidden = sess.run(ae['z'], feed_dict={\n",
    "             ae['x']: test_xs, ae['corrupt_prob']: [0.0]})\n",
    "    \n",
    "    #prep for knn\n",
    "    nn=[]\n",
    "    for h,y in zip(hidden,test_ys):\n",
    "        l = h.tolist()+[get_label(y.tolist())]\n",
    "        nn.append(l)\n",
    "        \n",
    "    return nn,hidden,test_ys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "\n",
    "Algorithm to get euclidean distance to nearest neighbor and predict label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclideanDistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += pow((instance1[x] - instance2[x]), 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedVotes\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        #print(\"Label\",testSet[x][-1])\n",
    "        #print(\"Prediction\",predictions[x][0][0])\n",
    "        if testSet[x][-1] is predictions[x][0][0]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "def knn(nn):\n",
    "    print(len(nn))\n",
    "    predictions=[]\n",
    "    k=2\n",
    "    for x in range(len(nn)):   \n",
    "        neighbors = getNeighbors(nn, nn[x], k)\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "        print('>',x,'predicted=' + repr(result) + ', actual=' + repr(nn[x][-1]))\n",
    "    accuracy = getAccuracy(nn, predictions)\n",
    "    print('Accuracy: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE\n",
    "\n",
    "Algorithm to visualize graphical representaiton of 30 dim vector embeddings in lower dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_labels(lowDWeights, labels, filename='tsne.png'):\n",
    "    assert lowDWeights.shape[0] >= len(labels), \"More labels than weights\"\n",
    "    plt.figure(figsize=(20, 20))  #in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = lowDWeights[i,:]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label,\n",
    "                 xy=(x, y),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='right',\n",
    "                 va='bottom')\n",
    "\n",
    "    plt.savefig(filename)\n",
    "        \n",
    "def tsne(X,labels):\n",
    "    print(\"Computing t-SNE\")\n",
    "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    plot_only = 2000\n",
    "    X_tsne = tsne.fit_transform(X[0:plot_only,:])\n",
    "    l = [str(get_label(l_i)) for l_i in labels[0:plot_only]]\n",
    "    \n",
    "    plot_with_labels(X_tsne, l, \"t-SNE embedding of the digits\")\n",
    "\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "\n",
    "Beginning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    nn,X,labels = train_mnist(start_epoch=0,n_epochs = 10, restore=False, save=True)\n",
    "    knn(nn)\n",
    "    tsne(X,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
